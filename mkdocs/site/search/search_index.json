{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Proves amb orquestradors de contenidors","text":"<p>Repositori del projecte: https://github.com/josanescod/tfg-kvbox</p>"},{"location":"#distribucions-de-kubernetes-utilitzades-i-proves","title":"Distribucions de Kubernetes utilitzades i proves:","text":""},{"location":"#proves-realitzades-en-un-entorn-local","title":"Proves realitzades en un entorn local.","text":"<ul> <li>microk8s</li> <li>minikube</li> <li>k0s</li> <li>k3s</li> <li>kind</li> <li>kubeadm</li> </ul>"},{"location":"#proves-realitzades-en-un-entorn-remot","title":"Proves realitzades en un entorn remot.","text":"<ul> <li>vps1</li> <li>vps2</li> </ul>"},{"location":"references/","title":"Refer\u00e8ncies","text":""},{"location":"references/#documentacio-web","title":"Documentaci\u00f3 web","text":"<ul> <li>Bitnami Sealed Secrets \u2014 Kubernetes Secret Management</li> <li>Docker</li> <li>httpd</li> <li>Installing kubeadm</li> <li>Creating a cluster with kubeadm</li> <li>K0s</li> <li>K3s</li> <li>Kind</li> <li>Kubernetes/ingress-nginx</li> <li>Microk8s</li> <li>Minikube</li> <li>MKDocs</li> <li>NGINX Docs </li> <li>Pr\u00e1ctica: MkDocs. Implantaci\u00f3n de Aplicaciones Web</li> <li>squidfunk/mkdocs-material</li> </ul>"},{"location":"references/#videotutorials","title":"Videotutorials","text":"<ul> <li>Tutorial Kubernetes | De 0 a 100 con K0s | formaci\u00f3n 100% practica</li> <li>Tutorial Kubernetes II | Desde los Volumenes o Ingress a los DaemonSets | formaci\u00f3n 100% practico</li> <li>Helm, el gestor de paquetes para Kubernetes: De 0 a empaquetar aplicaciones en un solo v\u00eddeo</li> </ul>"},{"location":"local_test/k0s/","title":"Desplegament d'un cl\u00faster de Kubernetes amb k0s","text":"<p>V\u00eddeo a la prova realitzada: Desplegament d'un cl\u00faster de Kubernetes amb k0s en un entorn local</p>"},{"location":"local_test/k0s/#objectiu","title":"Objectiu","text":"<p>Desplegar un cl\u00faster de Kubernetes amb la distribuci\u00f3 k0s i practicar els conceptes de Ingress Controller, Ingress, Persistent Volume, Persistent Volume Claim. </p>"},{"location":"local_test/k0s/#creacio-del-cluster","title":"Creaci\u00f3 del cl\u00faster","text":"<pre><code># control plane\nmkdir -p /etc/k0s\nk0s config create &gt; /etc/k0s/k0s.yaml\nsudo k0s install controller --enable-worker -c /etc/k0s/k0s.yaml\nsudo k0s start\nsudo k0s token create --role=worker\n\n# worker\ncopiar el token a un fitxer token.txt\nsudo k0s install worker --token-file token.txt\nsudo k0s start\n\n# control plane\nsudo k0s run worker\nkubectl label node worker1 node-role.kubernetes.io/worker=worker\n</code></pre>"},{"location":"local_test/k0s/#ingress-controller","title":"Ingress Controller","text":"<p>Un Ingress Controller \u00e9s una aplicaci\u00f3 que s'executa en un cl\u00faster i configura el balanceig de c\u00e0rrega http segons els recursos Ingress. Es pot configurar de diverses maneres, en un entorn baremetal sense loadBalancers de proveidors hi ha diverses solucions amb els seus pros i contres, explicats a la documentaci\u00f3 oficial, per al v\u00eddeo de proves s'utilitza la guia de k0s on s'instal\u00b7la un NGINX Ingress Controller utilitzant NodePort.</p> <p>Per la instal\u00b7laci\u00f3 m'he basat en dues fonts:</p> <ul> <li>la documentaci\u00f3 oficial de k0s: Installing NGINX Ingress Controller </li> <li>la guia d'instal\u00b7laci\u00f3 del repositori de ingress-nginx: Installation Guide.</li> </ul> <pre><code># Instal\u00b7laci\u00f3 per entorns baremetal\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.1.3/deploy/static/provider/baremetal/deploy.yaml\nkubectl get pods -n ingress-nginx\nkubectl get services -n ingress-nginx\nkubectl -n ingress-nginx get ingressclasses\n\n# Anotaci\u00f3 per entorns on s'executa un \u00fanic controlador\nkubectl -n ingress-nginx annotate ingressclasses nginx ingressclass.kubernetes.io/is-default-class=\"true\"\n\n# Verificar el funcionament\ncurl &lt;worker-external-ip&gt;:&lt;node-port&gt;\n</code></pre>"},{"location":"local_test/k0s/#ingress-recurs-de-kubernetes","title":"Ingress (recurs de Kubernetes)","text":"<p>Ingress \u00e9s un recurs de Kubernetes que permet exposar i gestionar sol\u00b7licituds a diferents serveis segons el seu URL. </p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /$1\n    nginx.ingress.kubernetes.io/enable-cors: \"false\"\n    nginx.ingress.kubernetes.io/backend-protocol: HTTP\n  name: web-server-ingress\n\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: cluster.test.dev\n    http:\n      paths:\n      - path: /app1/(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: nodeapp-service\n            port:\n              number: 3000\n      - path: /app2/(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: nodeapp2-service\n            port:\n              number: 4000\n      - path: /docs/(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: docs-service\n            port:\n              number: 5000\n</code></pre>"},{"location":"local_test/k0s/#persistence-volume","title":"Persistence Volume","text":"<p>Un Persistence Volume \u00e9s un recurs de Kubernetes que representa un volum d'emmagatzematge persistent, com un disc o espai d'emmagatzematge al n\u00favol. \u00c9s una abstracci\u00f3 que permet a les aplicacions sol\u00b7licitar espai d'emmagatzematge.</p> <pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: my-pv\nspec:\n  capacity:\n    storage: 2Gi\n  volumeMode: Filesystem\n  accessModes:\n    - ReadWriteOnce\n  hostPath:\n    path: /path/to/host/folder\n</code></pre>"},{"location":"local_test/k0s/#persistence-volume-claim","title":"Persistence Volume Claim","text":"<p>Un Persistence Volume Claim \u00e9s un objecte de Kubernetes que representa una sol\u00b7licitud de recursos d'emmagatzematge. Ha d'haver-hi un PV per poder vincular un PVC.</p> <pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: my-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 1Gi\n</code></pre>"},{"location":"local_test/k0s/#exemple-pv-i-pvc","title":"Exemple PV i PVC","text":"<ol> <li>Es defineix un Persistent Volume 'my-pv'</li> <li>Es defineix un Persistent Volume Claim 'my-pvc'</li> <li>Un deployment pot utilitzar un pvc a trav\u00e9s d'un volum 'my-storage'</li> </ol> <pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: my-pv\nspec:\n  capacity:\n    storage: 5Gi\n  volumeMode: Filesystem\n  accessModes:\n    - ReadWriteOnce\n  hostPath:\n    path: /path/to/host/folder\n\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: my-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 3Gi\n\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-container\n        image: nginx\n        volumeMounts:\n        - name: my-storage\n          mountPath: /usr/share/nginx/html\n  volumes:\n  - name: my-storage\n    persistentVolumeClaim:\n      claimName: my-pvc\n</code></pre>"},{"location":"local_test/k3s/","title":"Desplegament d'un cl\u00faster de Kubernetes amb K3s","text":"<p>V\u00eddeo a la prova realitzada: Desplegament d'un servei web en un entorn local amb K3s</p>"},{"location":"local_test/k3s/#objectiu","title":"Objectiu","text":"<p>L'objectiu \u00e9s crear una p\u00e0gina de documentaci\u00f3 de prova, generada amb MKDocs, afegir-la a un contenidor, i configurar un fitxer manifest de kubernetes per desplegar un pod i un servei de tipos NodePort dins d'un c\u00faster de K3s.</p>"},{"location":"local_test/k3s/#creacio-de-lestructura-de-fitxers-amb-el-contenidor-squidfunkmkdocs-material","title":"Creaci\u00f3 de l'estructura de fitxers amb el contenidor squidfunk/mkdocs-material","text":"<pre><code>docker run --rm -it -p 8000:8000 -v \"$PWD\":/docs squidfunk/mkdocs-material new .\n</code></pre>"},{"location":"local_test/k3s/#modificacio-del-contingut-en-format-markdown","title":"Modificaci\u00f3 del contingut en format markdown","text":"<p>Creaci\u00f3 del contingut en els fitxers md i el fitxer de configuraci\u00f3 mkdocs.yml.</p>"},{"location":"local_test/k3s/#generacio-de-la-documentacio","title":"Generaci\u00f3 de la documentaci\u00f3","text":"<pre><code>docker run --rm -it -v \"$PWD\":/docs squidfunk/mkdocs-material build\n</code></pre>"},{"location":"local_test/k3s/#creacio-dun-fitxer-manifest-per-a-kubernetes-amb-un-servei-per-exposar-laplicacio-dins-dun-cluster-de-k3s","title":"Creaci\u00f3 d'un fitxer manifest per a kubernetes amb un Servei per exposar l'aplicaci\u00f3 dins d'un cluster de k3s","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: web1\n  labels:\n    app: web\nspec:\n  containers:\n    - name: webtest\n      image: https:alpine\n      ports:\n        - containerPort: 80\n      volumeMounts:\n        - name: html-volume\n          mountPath: /usr/local/apache2/htdocs\n  volumes:\n    - name: html-volume\n      hostPath:\n        path: /home/vagrant/mkdocs/site\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: service1\nspec:\n  type: NodePort\n  selector:\n    app: web\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n      nodePort: 30000\n</code></pre>"},{"location":"local_test/k3s/#comanda-per-desplegar-el-servei","title":"Comanda per desplegar el servei","text":"<pre><code>kubectl apply -f docu_service.yaml \n</code></pre>"},{"location":"local_test/kind/","title":"Desplegament d'un cl\u00faster de Kubernetes amb Kind","text":"<p>V\u00eddeo a la prova realitzada: Proves amb kind: daemonset, job, cronjob, configmap i secrets.</p>"},{"location":"local_test/kind/#objectiu","title":"Objectiu","text":"<p>Crear un cl\u00faster amb Kind i provar alguns dels recursos de la seva API: daemonSet, job, cronjob, configmap i secret.</p> <p>Com que Kind \u00e9s una distribuci\u00f3 de Kubernetes basada en contenidors docker, en aquesta ocasi\u00f3 nom\u00e9s s'utilitzar\u00e0 una m\u00e0quina virtual de l'entorn de proves.</p>"},{"location":"local_test/kind/#creacio-del-cluster","title":"Creaci\u00f3 del cl\u00faster","text":"<p>Creem un fitxer kind-example-config.yaml amb el seg\u00fcent contingut:</p> <pre><code>apiVersion: kind.x-k8s.io/v1alpha4\nkind: Cluster\nnodes:\n- role: control-plane\n- role: worker\n- role: worker\n  extraPortMappings:\n  - containerPort: 30000\n    hostPort: 7000\n</code></pre> <p>kind create cluster --config kind-example-config.yaml</p> <p>export KUBECONFIG per poder utilizar kubectl</p>"},{"location":"local_test/kind/#etiquetes-de-rol-als-dos-nodes-workers","title":"Etiquetes de rol als dos nodes workers","text":"<pre><code>kubectl label node kind-worker node-role.kubernetes.io/worker=worker\nkubectl label node kind-worker2 node-role.kubernetes.io/worker=worker\n</code></pre>"},{"location":"local_test/kind/#crear-un-daemonset-amb-fluentd","title":"Crear un DaemonSet amb Fluentd","text":"<p>Un DaemonSet \u00e9s un recurs de Kubernetes que s'assegura que a cada node del cl\u00faster es desplegui una c\u00f2pia d'un pod.  S'utilitza per recol\u00b7lecci\u00f3 de logs, monitoratge de nodes o per executar processos relacionats amb volums, en segon pla. </p> <p><pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd\n  namespace: default\n  labels:\n    app: fluentd\nspec:\n  selector:\n    matchLabels:\n      name: fluentd\n  template:\n    metadata:\n      labels:\n        name: fluentd\n    spec:\n      containers:\n      - name: fluentd\n        image: fluentd:latest\n</code></pre> kubectl apply -f daemonset.yaml kubectl get daemonsets kubectl get pods -n default -o wide</p>"},{"location":"local_test/kind/#job","title":"Job","text":"<p>Un Job \u00e9s un recurs que pot crear 1 o m\u00e9s pods per executar tasques en paral.lel. S'utilitza en casos que es requereix executar processos batch, c\u00e0lculs d'operacions que requereixen gran quantitat de recursos de computaci\u00f3. Alguns exemples s\u00f3n: c\u00e0lculs de decimals del nombre pi, consultes a bases de dades, renderitzaci\u00f3, etc.</p> <p><pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: my-job\nspec:\n  template:\n    metadata:\n      name: my-job\n    spec:\n      containers:\n      - name: containerjob\n        image: alpine\n        command:\n        - \"/bin/sh\"\n        - \"-c\"\n        args:\n        - |\n          apk --no-cache add ca-certificates curl jq\n          update-ca-certificates\n          curl -H \"Accept: application/json\" https://swapi.dev/api/people/?search=yoda | jq '.results[] | { name, homeworld, species }'\n      restartPolicy: Never\n</code></pre> kubectl apply -f job.yaml</p>"},{"location":"local_test/kind/#cronjob","title":"Cronjob","text":"<p>Un Cronjob \u00e9s similar a un Job, per\u00f2 que es planifica perqu\u00e8 es repeteixi peri\u00f2dicament.</p> <p><pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  schedule: \"*/1 * * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: hello\n            image: busybox\n            args:\n            - /bin/sh\n            - -c\n            - date; echo Hello from the Kubernetes cluster\n          restartPolicy: OnFailure\n</code></pre> kubectl apply -f cronjob.yaml</p>"},{"location":"local_test/kind/#configmap","title":"ConfigMap","text":"<p>Un ConfigMap \u00e9s un recurs de Kubernetes que permet emmagatzemar dades de configuraci\u00f3 com ara variables d'entorn, nombre de ports, entre d'altres i poder-los aplicar en altres fitxers manifests.</p> <p><pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: my-configmap\ndata:\n  VARIABLE1: mongodb\n  VARIABLE2: redis\n</code></pre> kubectl apply -f config_map.yaml i despr\u00e9s es pot referenciar la configuraci\u00f3 a altres fitxers manifest.</p> <p><pre><code>  containers:\n  - name: container1\n    image: nginx:alpine\n    volumeMounts:\n    - name: config-volume\n      mountPath: /usr/share/nginx/html\n    envFrom:\n    - configMapRef:\n        name: my-configmap\n</code></pre> Es poden crear aplicant kubectl apply -f configmap.yaml (mode declaratiu) o b\u00e9 a trav\u00e9s de la l\u00ednia de d'ordres com la majoria d'objectes de Kubernetes (mode imperatiu).</p>"},{"location":"local_test/kind/#secret","title":"Secret","text":"<p>Un Secret \u00e9s un objecte de Kubernetes que s'utilitza per emmagatzemar informaci\u00f3 confidencial, com contrasenyes o tokens d'una API. Es poden referenciar els seus valors com a variables d'entorn o b\u00e9 muntar els seus valors en volums.</p> <p>Es pot codificar/decodificar:</p> <p><pre><code>echo -n \"Tyrion\" | base64\necho -n \"VHlyaW9u\" | base64 --decode\n</code></pre> \u00c9s important destacar, que no \u00e9s una manera d'encriptar dades cr\u00edtiques, s'utilitza m\u00e9s aviat per ofuscar la informaci\u00f3, representar dades en un conjunt est\u00e0ndard de car\u00e0cters, permetre incloure dades bin\u00e0ries o sensibles directament als manifests i \u00e9s una manera estandarditzada de compartir informaci\u00f3, per\u00f2 es recomana afegir capes de seguretat per a dades delicades.</p> <p><pre><code>apiVersion: v1\ndata:\n  username: VHlyaW9u\n  password: TGFubmlzdGVy\nkind: Secret\nmetadata:\n  creationTimestamp: \"2023-11-27T19:32:18Z\"\n  name: my-secret\n  namespace: default\n  resourceVersion: \"49319\"\n  uid: f62ae573-a38e-4dc4-beae-198752c267de\ntype: Opaque\n</code></pre> kubectl apply -f my-secret.yaml</p> <p>o b\u00e9 de forma imperativa '''kubectl create secret generic my-secret --from-literal=username=my-username --from-literal=password=my-password -o yaml &gt;&gt; my-secret.yaml'''</p> <p>Una vegada es crea el secret es pot afegir als manifests yamls, com per exemple a un pod:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx:alpine\n    envFrom:    \n    - secretRef:\n        name: my-secret\n</code></pre>"},{"location":"local_test/kind/#secret-encriptat-amb-kubeseal","title":"Secret encriptat amb kubeseal","text":"<p>Com que els secrets estan codificats en base64, per afegir una capa extra de seguretat es poden encriptar amb eines com kubeseal. </p> <p>Aquesta eina permet encriptar secrets amb un certificat, i despr\u00e9s el mateix cl\u00faster s'encarrega de desencriptar-lo. Pot ser una bona pr\u00e0ctica quan es pengen secrets a repositoris (encara que siguin privats).</p> <p>Una vegada tenim descarregat el client i el Sealed Secrets Controller, podem crear un secret:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  creationTimestamp: null\n  name: my-secret-2\n  namespace: default\ndata:\n  password: ZWxkZXNlbXByZQ==\n  username: MTIzNDU=\n</code></pre> <p>Obtenim la clau p\u00fablica del certificat</p> <pre><code>kubeseal --fetch-cert &gt; public-key-cert.pem\n</code></pre> <p>Encriptem el fitxer yaml del secret</p> <pre><code>kubeseal --format=yaml --cert=public-key-cert.pem &lt; secret.yaml &gt; sealed-secret.yaml\n</code></pre> <p>y quedaria de la seg\u00fcent manera:</p> <p><pre><code>apiVersion: bitnami.com/v1alpha1\nkind: SealedSecret\nmetadata:\n  creationTimestamp: null\n  name: my-secret-2\n  namespace: default\nspec:\n  encryptedData:\n    password: AgAk4Jq54VeRuFhzGPO3784Nqx7iAPg8+gnMTM2dFHXFTg1RzNXOYg0kib7OWSq85rhhqXNpPiOLf9Ex5urT3xqnwcvcW4ZPA3ZOrYvm8lEc2M00PZlQVNEmNEt8aqDQ+8GaU2IUrspV5KJhuhq4MzlWRnxTfDmsQ1bxj/8k8jpX0knbLQ7+lvZAbGzXvqR0WDqw24wylqu3ZwtWCeJs4aif1WyOQUNNkx0NgzLkbVSpWm9Ri6523AkwZbbuLNdugZyBuDB+PO2fDM6eJ8pjLjqLH/RwCPFVvposuLlqGBzZqBE799C1mt6fVVTBaso8pPR6rW3CgA48ZzXLmAaXprJ3D/yJjL6KQnUX0TaasLiPPCxkGXqNmuKWVs6pCaQZSBT1lF1rFNQ2rG1GsimOr/ngfpyqZbqS7BJicYVRz01AtmTVuild8LxYXeGiMVo9wBSLOqc/UrTP95mjsWiGj6jnlXr1sJk8TZMTZMgBKqJZvOglRE5sxJp0JSVkpwj/PAajGYloLn9Ue7jXOw3frudnSpwoA7n6ZBmhiRODp6tji/m/CeSXplGyrlk3fDMcj+iqodfXa58FkFHC+TXRZuKEzxbSCKUzzT7B2NCeZcMNZEu/bo5Ys6N03VQKYq1g1IYhlGNPZTxZ3bLbPZtD0CnEvIDaUg+bTed0L+SSZ9Lx+qWsB9EhpITvsHxz8C5qZqNy9nP8CO3UgQnf\n    username: AgAc57N+49tg7RBHpSCf7Ped7ZAeEL3WJ3K7LfOzvp4iG2oeCRBrUt8bj99Im9s7laLzIs0vQQZFd17XqC08r4yFmHly/bezH4dAotVfzUpZ1gqTR63qfCE9YPX0TboaqKcnlYdDPZgt9qlIId1xc0PImVHQVr+6R421X90xkY8WhnXPlC1c8voiah34AuEfu+BDsY0OExDxoDcJYuTmlxFb75n7c5W+Zc3HO8SuwBIQVAcRL8m3NQelky9DTNMjvG5pMpLsAqstPu6rX8Lg0BvMzSG4ns3h97ao/H55rfJK5vBIK8UzMM9DkB2xTT+BN48NdNqHR6Szyc9qQLynuTczEIHh+LyhB31RsVp9Ogb4upuCaiJu2OrvrdKmsutiaT3qKq9qxtuBTX9jbe7mqZUZkY3JiPS/JiTsxKJwJdOJvMXByKkFUfijAaouXKByiaSdB2xjCuZ8Fnl4cu5kk71S/6B/ftcOFHrEyqiHPKh1WUkFi4qh5vOtyUtHNFlGGtnDXEiBv+R6j509lCclR05byLmfGMnjv7np6n86hjULcpPxqdi9B07sGIb1dGtu9MEi59v0EfenVvDZT88AlKd2Dl65sQyaNC2akwxTuop7wIQ+xrzyt5EFRsLin7TSN/w7HT1JXROJ2zLs5c92V/XkYsze23deexuuasfIt9Av6ytVGFug9xjRaTOpJeMX8A1lo5vaOQ==\n  template:\n    metadata:\n      creationTimestamp: null\n      name: my-secret-test\n      namespace: default\n</code></pre> kubectl delete -f secret.yaml</p> <p>kubectl apply -f sealed-secret.yaml</p> <p>A partir d'aquest moment es pot esborrar el secret i aplicar el secret encriptat. S'ha de tenir present que el secret i el secret sealed han d'estar en el mateix namespace.</p> <p>Finalment, quan es faci \u00fas del secret sealed, el cl\u00faster, descodificar\u00e0 autom\u00e0ticament les contrasenyes encriptades.</p>"},{"location":"local_test/kubeadm/","title":"Desplegament d'un cl\u00faster de Kubernetes amb kubeadm","text":"<p>V\u00eddeo a la prova realitzada: Desplegament d'un cl\u00faster de Kubernetes amb kubeadm en un entorn local</p>"},{"location":"local_test/kubeadm/#objectiu","title":"Objectiu","text":"<p>Desplegar un cl\u00faster de Kubernetes amb kubeadm i practicar els conceptes metalLoadBalancer, Nginx Ingress Controller.</p>"},{"location":"local_test/kubeadm/#installacio-pas-a-pas-de-kubernetes-amb-kubeadm","title":"Instal\u00b7laci\u00f3 pas a pas de kubernetes amb kubeadm","text":""},{"location":"local_test/kubeadm/#controlplane","title":"Controlplane","text":"<p>Mode root</p> <pre><code>sudo -i\n</code></pre> <p>Actualitzar el sistema</p> <pre><code>apt update &amp;&amp; apt upgrade -y\n</code></pre> <p>Instal\u00b7lar paquets necessaris</p> <pre><code>apt install curl apt-transport-https vim git wget \\\nsoftware-properties-common lsb-release ca-certificates -y\n</code></pre> <p>Desactivar swap</p> <pre><code>swapoff -a\n</code></pre> <p>Carregar els seg\u00fcents m\u00f2duls:</p> <pre><code>modprobe overlay\nmodprobe br_netfilter\n</code></pre> <p>Actualitzar el kernel per permetre el tr\u00e0fic</p> <pre><code>cat &lt;&lt; EOF | tee /etc/sysctl.d/kubernetes.conf\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\nEOF\n</code></pre> <p>Verificar que els canvis s'han realitzat</p> <pre><code>sysctl --system\n</code></pre> <p>Instal\u00b7lar la clau necess\u00e0ria per a la instal\u00b7laci\u00f3</p> <pre><code>sudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg \\\n| sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\necho \\ \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \\\nhttps://download.docker.com/linux/ubuntu \\\n$(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre> <p>Instal\u00b7lar containerd</p> <pre><code>apt-get update &amp;&amp; apt-get install containerd.io -y\ncontainerd config default | tee /etc/containerd/config.toml\nsed -e 's/SystemdCgroup = false/SystemdCgroup = true/g' -i /etc/containerd/config.toml\nsystemctl restart containerd\n</code></pre> <p>Crear un nou repositori per a Kubernetes</p> <pre><code>echo 'deb https://packages.cloud.google.com/apt kubernetes-xenial main' &gt; /etc/apt/sources.list.d/kubernetes.list\n</code></pre> <p>Afegir la clau GPG per als paquets:</p> <pre><code>curl -fsSL \"https://packages.cloud.google.com/apt/doc/apt-key.gpg\" | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/kubernetes-archive-keyring.gpg\n</code></pre> <p>Actualitzar i instal\u00b7lar kubeadm, kubectl i kubelet</p> <pre><code>apt update -y\napt install kubeadm kubectl kubelet\n</code></pre> <p>Configurar els paquets perqu\u00e8 no s'actualitzin</p> <pre><code>apt-mark hold kubelet kubeadm kubectl\n</code></pre> <p>Afegir un DNS local al servidor controlplane</p> <pre><code># editar /etc/hosts\n\n172.16.2.5  controlplane\n</code></pre> <p>Crear un fitxer de configuraci\u00f3 pel cl\u00faster</p> <pre><code># vim kubeadm-config.yaml\n\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: 1.28.2\ncontrolPlaneEndpoint: \"controlplane:6443\"\nnetworking:\n  podSubnet: 172.16.2.0/24 \n</code></pre> <p>Inicialitzar el node controlplane</p> <pre><code>kubeadm init --config=kubeadm-config.yaml --upload-certs | tee kubeadm-init.out\n</code></pre> <p>Logout root i configurar l'usuari com administrado del cl\u00faster</p> <pre><code>logout\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\nless .kube/config\n</code></pre> <p>Instal\u00b7lar el gestor de paquets Helm</p> <pre><code>wget https://get.helm.sh/helm-v3.13.2-linux-amd64.tar.gz\ntar -zxvf helm-v3.13.2-linux-amd64.tar.gz\nmv linux-amd64/helm /usr/local/bin/helm\n</code></pre> <p>Seleccionar un pod de xarxa per al CNI (Container Networkin Interface) hi ha diversos, Cilium o Calico s\u00f3n bastant populars.</p> <pre><code>helm repo add cilium https://helm.cilium.io/\nhelm repo update\nhelm template cilium cilium/cilium --namespace kube-system &gt; cilium.yaml\nkubectl apply -f cilium.yaml\n</code></pre> <p>Instal\u00b7lar autocompletat</p> <pre><code>sudo apt-get install bash-completion -y\nsource &lt;(kubectl completion bash)\necho \"source &lt;(kubectl completion bash)\" &gt;&gt; $HOME/.bashrc\n</code></pre>"},{"location":"local_test/kubeadm/#worker1","title":"Worker1","text":"<p>Repetir els mateixos passos que al node anterior des de l'inici fins a afegir un DNS local al node worker</p> <p>Mode root</p> <pre><code>sudo -i\n</code></pre> <p>Actualitzar el sistema</p> <pre><code>apt update &amp;&amp; apt upgrade -y\n</code></pre> <p>Instal\u00b7lar paquets necessaris</p> <pre><code>apt install curl apt-transport-https vim git wget \\\nsoftware-properties-common lsb-release ca-certificates -y\n</code></pre> <p>Desactivar swap</p> <pre><code>swapoff -a\n</code></pre> <p>Carregar els seg\u00fcents m\u00f2duls</p> <pre><code>modprobe overlay\nmodprobe br_netfilter\n</code></pre> <p>Actualitzar el kernel per permetre el tr\u00e0fic</p> <pre><code>cat &lt;&lt; EOF | tee /etc/sysctl.d/kubernetes.conf\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\nEOF\n</code></pre> <p>Verificar que els canvis s'han realitzat</p> <pre><code>sysctl --system\n</code></pre> <p>Instal\u00b7lar la clau necess\u00e0ria per a la instal\u00b7laci\u00f3</p> <pre><code>sudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg \\\n| sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\necho \\ \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \\\nhttps://download.docker.com/linux/ubuntu \\\n$(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre> <p>Install containerd</p> <pre><code>apt-get update &amp;&amp; apt-get install containerd.io -y\ncontainerd config default | tee /etc/containerd/config.toml\nsed -e 's/SystemdCgroup = false/SystemdCgroup = true/g' -i /etc/containerd/config.toml\nsystemctl restart containerd\n</code></pre> <p>Crear un nou repositori per a Kubernetes</p> <pre><code>echo 'deb https://packages.cloud.google.com/apt kubernetes-xenial main' &gt; /etc/apt/sources.list.d/kubernetes.list\n</code></pre> <p>Afegir la clau GPG per als paquets:</p> <pre><code>curl -fsSL \"https://packages.cloud.google.com/apt/doc/apt-key.gpg\" | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/kubernetes-archive-keyring.gpg\n</code></pre> <p>Actualitzar i instal\u00b7lar kubeadm, kubectl i kubelet</p> <pre><code>apt update -y\napt install kubeadm kubectl kubelet\n</code></pre> <p>Configurar els paquets perqu\u00e8 no s'actualitzin</p> <pre><code>apt-mark hold kubelet kubeadm kubectl\n</code></pre> <p>Afegir un DNS local al servidor controlplane</p> <pre><code># editar /etc/hosts\n172.16.3.5  worker1\n172.16.2.5  controlplane\n</code></pre> <p>Per unir el worker al cl\u00faster del controlplane es pot utilitzar la instrucci\u00f3 join amb el token inicial que mostra la primera vegada el controlplane o b\u00e9 generar un nou token <pre><code>sudo kubeadm token list\n</code></pre></p> <p>Creaci\u00f3 d'un nou token (al controlplane)</p> <pre><code>sudo kubeadm token create\n</code></pre> <p>Generaci\u00f3 del discovery token CA cert hash per permetre la uni\u00f3 del node worker</p> <pre><code>openssl x509 -pubkey \\\n-in /etc/kubernetes/pki/ca.crt | openssl rsa \\\n-pubin -outform der 2&gt;/dev/null | openssl dgst \\\n-sha256 -hex | sed 's/^.* //'\n</code></pre> <p>Utilitzar el token i el discovery token al worker node</p> <pre><code>sudo -i\nkubeadm join --token 27eee4.6e66ff60318da929 controlplane:6443 \\\n--discovery-token-ca-cert-hash sha256:6d541678b05652e1fa5d43908e75e67376e994c3483d6683f2a18673e5d2a1b0\n</code></pre> <p>Anar al controlplane i verificar que tot funciona correctament</p> <pre><code>kubectl get node\nkubectl describe node controlplane\n</code></pre> <p>Permetre que controlplane pugui contenir pods que no siguin del sistema</p> <pre><code>kubectl taint nodes --all node-role.kubernetes.io/control-plane-\n</code></pre> <p>Verificar que cilium i coredns funcionen correctament</p> <pre><code>kubectl get pods --all-namespaces\n</code></pre> <p>Actualitzaci\u00f3 de crictl</p> <pre><code>sudo crictl config --set \\\nruntime-endpoint=unix:///run/containerd/containerd.sock \\\n--set image-endpoint=unix:///run/containerd/containerd.sock\n\nsudo cat /etc/crictl.yaml\n</code></pre>"},{"location":"local_test/kubeadm/#metallb-loadbalancer","title":"MetalLB (loadbalancer)","text":"<p>Verificar si kube-proxy es troba en mode IPVS</p> <pre><code>kubectl get configmap kube-proxy -n kube-system -o yaml\n</code></pre> <p>En cas afirmatiu afegir la seg\u00fcent configuraci\u00f3 afegir strictARP: true</p> <pre><code>kubectl edit configmap -n kube-system kube-proxyapiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind: KubeProxyConfiguration\nmode: \"ipvs\"\nipvs:\n  strictARP: true\n</code></pre> <p>Instal\u00b7lar MetalLB</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.12/config/manifests/metallb-native.yaml\n</code></pre> <p>Crear el fitxer de configuraci\u00f3 amb el pool d'adreces</p> <pre><code>apiVersion: metallb.io/v1beta1\nkind: IPAddressPool\nmetadata:\n  name: first-pool\n  namespace: metallb-system\nspec:\n  addresses:\n  - 172.16.2.240-172.16.2.250\n  autoAssign: true\n---\napiVersion: metallb.io/v1beta1\nkind: L2Advertisement\nmetadata:\n  name: default\n  namespace: metallb-system\nspec:\n  ipAddressPools:\n  - default\n</code></pre> <p>k apply -f metallb-config.yaml</p>"},{"location":"local_test/kubeadm/#nginx-ingress-controller","title":"Nginx Ingress Controller","text":"<p>Instal.laci\u00f3 Nginx Ingress Controller</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/cloud/deploy.yaml\n</code></pre> <p>Ingress-nginx service hauria de ser de tipus LoadBalancer, tenir EXTERNAL-IP i estar disponible fora del cl\u00faster.</p> <pre><code>kubectl -n ingress-nginx get svc\n\ncurl -D- http://172.16.2.250 -H 'Host: myapp.example.com'\n</code></pre>"},{"location":"local_test/kubeadm/#desplegar-una-aplicacio-de-prova","title":"Desplegar una aplicaci\u00f3 de prova","text":"<p>ConfigMap</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: my-configmap\ndata:\n  index.html: |\n    &lt;!DOCTYPE html&gt;\n    &lt;html&gt;\n    &lt;head&gt;\n      &lt;title&gt;My HTML Page&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n      &lt;h1&gt;Test Ingress Nginx amb External-IP&lt;/h1&gt;\n      &lt;p&gt;Funciona correctament.&lt;/p&gt;\n    &lt;/body&gt;\n    &lt;/html&gt;\n</code></pre> <p>Deployment</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:alpine\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: config-volume\n          mountPath: /usr/share/nginx/html\n      volumes:\n      - name: config-volume\n        configMap:\n          name: my-configmap\n          items:\n          - key: index.html\n            path: index.html\n</code></pre> <p>Service</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-service\nspec:\n  selector:\n    app: my-app\n  ports:\n  - protocol: TCP\n    port: 5000\n    targetPort: 80\n</code></pre> <p>Ingress</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations: {}\n  name: nginx-server-ingress\n\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: app1.cluster.test\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: nginx-service\n            port:\n              number: 5000\n</code></pre> <p>k apply -f test-configmap.yaml -f test-deployment.yaml -f test-service.yaml -f test-ingress yaml</p> <p>A la m\u00e0quina client editar /etc/hosts amb la ip externa de Nginx Ingress Controller proporcionada per MetalLB i el nom del host que s'ha configurat a la regla Ingress.</p> <pre><code># /etc/hosts\nEXTERNAL-IP app1.cluster.test\n</code></pre> <p>Realitzar una petici\u00f3 al servei</p> <pre><code>curl -D- http://EXTERNAL-IP -H 'Host: app1.cluster.test'\n</code></pre>"},{"location":"local_test/microk8s/","title":"Desplegament d'un cl\u00faster de Kubernetes amb MicroK8s","text":"<p>Video a la prova realitzada: Proves amb microk8s: statefulset i el gestor de paquets Helm </p>"},{"location":"local_test/microk8s/#objectiu","title":"Objectiu","text":"<p>Crear un cl\u00faster amb microk8s i provar diverses funcionalitats: </p>"},{"location":"local_test/microk8s/#creacio-del-cluster-amb-els-dos-nodes","title":"Creaci\u00f3 del cl\u00faster amb els dos nodes:","text":"<p>Al servidor controlplane:</p> <pre><code>microk8s start\nmicrok8s enable hostpath-storage\nmicrok8s enable dns\nmicrok8s add-node\n</code></pre> <p>La instrucci\u00f3 microk8s add-node generar\u00e0 un token per executar al segon servidor.</p> <p>Al servidor worker1:</p> <pre><code>microk8s join 172.16.2.5:25000/{token} --worker\n</code></pre>"},{"location":"local_test/microk8s/#statefulset","title":"StatefulSet","text":"<p>StatefulSet \u00e9s un objecte de la API de Kubernetes que representa un conjunt de pods que tenen un estat estable. Aix\u00f2 vol dir que tenen identificadors \u00fanics de xarxa, persist\u00e8ncia de dades, i mantenen un ordre a l'hora de desplegar-se, esborrar-se o actualitzar-se. S\u00f3n adequats per aplicacions com bases de dades. </p> <p>Estan formats per tres components, un Headless Service que \u00e9s un tipus de servei que no assigna direccions IP virtuals a un conjunt de pods. Els pods, i els persistent volume claims i els persistent volums, els objectes involucrats en la persist\u00e8ncia de dades.</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\nspec:\n  ports:\n  - port: 80\n    name: web\n  clusterIP: None\n  selector:\n    app: nginx\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  serviceName: \"nginx\"\n  replicas: 2\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: registry.k8s.io/nginx-slim:0.8\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n  - metadata:\n      name: www\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      resources:\n        requests:\n          storage: 1Gi\n</code></pre>"},{"location":"local_test/microk8s/#helm","title":"Helm","text":"<p>Helm \u00e9s un gestor de paquets per a Kubernetes. Els seus paquets s'anomenen charts, i permeten instal\u00b7lar, actualitzar, i desinstal\u00b7lar aplicacions dins dels cl\u00fasters f\u00e0cilment. Tamb\u00e9 permet crear charts i compartir-los. </p>"},{"location":"local_test/microk8s/#installacio-duna-aplicacio-amb-helm","title":"Instal\u00b7laci\u00f3 d'una aplicaci\u00f3 amb Helm","text":"<pre><code>helm repo add bitnami https://charts.bitnami.com/bitnami\nhelm show values bitnami/wordpress\n</code></pre> <p>Modificar els valors que siguin necessaris passant la configuraci\u00f3 en un fitxer values.yaml</p> <pre><code>wordpressUsername: admin\nwordpressPassword: wordpress\n</code></pre> <pre><code>helm install my-wordpress -f values.yaml bitnami/wordpress --version 18.1.19\n</code></pre> <pre><code>kubectl port-forward --address 0.0.0.0 service/my-wordpress 7000:8080\n</code></pre>"},{"location":"local_test/microk8s/#creacio-dun-chart-helm","title":"Creaci\u00f3 d'un chart-Helm","text":"<p>Helm tamb\u00e9 permet crear charts propis a partir de fitxers manifests, que despr\u00e9s es poden compartir.</p> <p>Els passos a seguir s\u00f3n:</p> <ul> <li>Creaci\u00f3 d'una carpeta per al projecte</li> </ul> <pre><code>mkdir my-chart\n</code></pre> <ul> <li>Dins de la carpeta executar helm create 'nom de l'aplicaci\u00f3'</li> </ul> <pre><code>helm create graph-solver\n</code></pre> <ul> <li>L' estructura de carpetes resultant \u00e9s la seg\u00fcent:</li> </ul> <p>carpeta chart: \u00e9s on anirien els charts dels que depengu\u00e9s el nostre Chart, es pot deixar igual.</p> <p>fitxer Chart.yaml: mostra informaci\u00f3 del Chart, es pot deixar o modificar els camps que es vulgui.</p> <p>carpeta templates: aqu\u00ed \u00e9s on aniran els fitxers manifests de la nostra aplicaci\u00f3, es poden esborrar els de mostra, nom\u00e9s deixar _helpers.tpl i NOTES.txt.</p> <p>El fitxer NOTES.txt es pot modificar per mostrar un missatge en finalitzar la instal\u00b7laci\u00f3.</p> <p>El fitxer _helpers.tpl es pot esborrar/modificar el seu contingut.</p> <p>A la carpeta de templates/tests tamb es pot esborrar el contigut.</p> <p>values.yaml: es pot esborrar el contigut i afegir els valors per defecte de les claus dels manifests que els usuaris podr\u00e0n modificar.</p> <pre><code>ReplicaCount: 1\nNodePortNumber: 30001\n</code></pre> <p>Al fitxer del deployment.yaml afegir els valors que volem que l'usuari pugui modificar en realitzar la instal\u00b7laci\u00f3:</p> <p><pre><code>spec:\n  replicas: {{ .Values.ReplicaCount }}\n  selector:\n    matchLabels:\n      app: graphsolver-app\n...\n\n- protocol: TCP\n    port: 8080\n    targetPort: 80\n    nodePort: {{ .Values.NodePortNumber }}\n  type: NodePort\n</code></pre> * Situar-se a un nivell superior de la carpeta de l'aplicaci\u00f3 i executar helm package graph-solver per empaquetar l'aplicaci\u00f3 i helm repo index per generar un fitxer index.yaml del repositori.</p> <pre><code>helm package graph-solver\n</code></pre> <pre><code>helm repo index .\n</code></pre> <p>A partir d'aqu\u00ed es pot penjar en el repositori oficial d'Helm o b\u00e9 penjarlo en un servidor web propi, en aquest cas per fer una prova es pot crear un contenidor docker i afegir el contingut.</p> <pre><code>docker run -dp 3000:80 -v $(pwd):/usr/local/apache2/htdocs/ --name repohelm httpd:alpine\n</code></pre>"},{"location":"local_test/microk8s/#installacio-del-chart-graph-solver","title":"Instal\u00b7laci\u00f3 del chart graph-solver","text":"<pre><code>helm repo add josan http://localhost:3000\nhelm show values josan/graph-solver\nhelm install graph-solver josan/graph-solver -f values2.yaml\nhelm list\n</code></pre>"},{"location":"local_test/microk8s/#desinstalacio-del-chart-i-el-repositori","title":"Desinstalaci\u00f3 del chart i el repositori","text":"<pre><code>helm uninstall graph-solver\nhelm repo remove josan\nhelm repo list\n</code></pre>"},{"location":"local_test/minikube/","title":"Desplegament d'un cl\u00faster de Kubernetes amb Minikube","text":"<p>Video a la prova realitzada: Proves amb minikube: deployment, autoescaling, rollout. </p>"},{"location":"local_test/minikube/#objectiu","title":"Objectiu","text":"<p>Crear un cl\u00faster amb minikube i provar diverses funcionalitats: deployment, autoescaling, rollout.</p>"},{"location":"local_test/minikube/#crear-un-cluster-de-kubernetes-amb-3-nodes","title":"Crear un cluster de kubernetes amb 3 nodes.","text":"<pre><code>minikube start -n 3\n</code></pre>"},{"location":"local_test/minikube/#activar-dos-addons-de-minikube-metriques-i-dashboard","title":"Activar dos addons de minikube: m\u00e8triques i dashboard.","text":"<pre><code>minikube addons list\nminikube addons enable metrics-server\nminikube addons enable dashboard\n</code></pre>"},{"location":"local_test/minikube/#etiquetes-de-rol-als-dos-nodes-workers","title":"Etiquetes de rol als dos nodes workers.","text":"<pre><code>kubectl label node minikube-m02 node-role.kubernetes.io/worker=worker\nkubectl label node minikube-m03 node-role.kubernetes.io/worker=worker\n</code></pre>"},{"location":"local_test/minikube/#treballar-en-un-nou-namespace-test","title":"Treballar en un nou namespace 'test'.","text":"<p>Un namespace \u00e9s una subdivisi\u00f3 virtual d'un cl\u00faster, permet separar i organitzar els recursos segons diferents prop\u00f2sits, com ara testing, desenvolupament, producci\u00f3. Si s'esborra un namespace, s'esborren tamb\u00e9 tots els seus recursos (pods, services, deployments, etc.)</p> <p>Un context defineix si un cl\u00faster \u00e9s local o remot, l'usuari que hi t\u00e9 acc\u00e9s, i un namespace predeterminat. S'utilitza per canviar r\u00e0pidament en entorns amb diferents cl\u00fasters o en entorns dins de Kubernetes.</p> <pre><code>kubectl get namespaces\nkubectl create namespace testing\nkubectl config view | grep current-context\nkubectl config set-context minikube --namespace=testing\n</code></pre>"},{"location":"local_test/minikube/#crear-un-deployment-amb-3-pods","title":"Crear un deployment amb 3 pods.","text":"<p>Un deployment \u00e9s un recurs de Kubernetes que defineix l'estat desitjat per a les aplicacions en execuci\u00f3 d'un cl\u00faster. Permet declarar, actualitzar i escalar aplicacions.</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-node-deployment\n  labels:\n    app: my-node\nspec: \n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-node\n  template:\n    metadata:\n      labels:\n        app: my-node\n    spec:\n      containers:\n      - name: my-node-container\n        image: josanescod/node-simple-app:1.0\n        ports:\n        - containerPort: 3000\n</code></pre> <p>kubectl apply -f deployment1.yaml kubectl describe pods | grep 'Image'</p>"},{"location":"local_test/minikube/#eliminar-un-pod-i-veure-com-kubernetes-ho-detecta-i-torna-a-crear-un-de-nou","title":"Eliminar un pod i veure com kubernetes ho detecta i torna a crear un de nou.","text":"<pre><code>kubectl delete pod my-node-deployment-79dd7879c7-5qb4c\nkubectl get pods\n</code></pre>"},{"location":"local_test/minikube/#autoescaling-manual-augmentar-i-disminuir-la-quantitat-de-pods","title":"Autoescaling manual: augmentar i disminuir la quantitat de pods.","text":"<pre><code>kubectl scale --replicas 5 deployment.apps/my-node-deployment\nkubectl scale --replicas 2 deployment.apps/my-node-deployment\n</code></pre>"},{"location":"local_test/minikube/#crear-un-servei-de-tipus-nodeport-per-exposar-els-pods-fora-del-cluster","title":"Crear un servei de tipus NodePort per exposar els pods fora del cl\u00faster.","text":"<p>Un servei de tipus NodePort proporciona una IP interna, i obre un port a cada node del cl\u00faster, que permet accedir al servei des de fora del cl\u00faster utilitzant la IP del node i el port assignat.</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-node-service\nspec:\n  selector:\n    app: my-node\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 3000\n  type: NodePort\n</code></pre> <p>kubectl apply -f service.yaml</p>"},{"location":"local_test/minikube/#mostrar-en-un-navegador-laplicacio-my-node-app-amb-kubectl-port-forward","title":"Mostrar en un navegador l'aplicaci\u00f3 my-node-app amb kubectl port-forward","text":"<pre><code>kubectl get svc\nip=$(minikube ip)\ncurl $ip:NodePort\n\nkubectl port-forward --address 0.0.0.0 7000:80\nobrir el navegador amb l'adre\u00e7a http://172.16.2.5:7000\n</code></pre>"},{"location":"local_test/minikube/#executar-un-segon-deployment-que-fa-un-rollout-dels-pods","title":"Executar un segon deployment que fa un rollout dels pods","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-node-deployment\n  labels:\n    app: my-node\nspec: \n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-node\n  minReadySeconds: 20\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  template:\n    metadata:\n      labels:\n        app: my-node\n    spec:\n      containers:\n      - name: my-node-container\n        imagePullPolicy: Always\n        image: josanescod/node-simple-app:2.0\n        ports:\n        - containerPort: 3000\n</code></pre> <p>Un rollout \u00e9s una actualitzaci\u00f3 d'un deployment de manera controlada i gradual.</p> <p>minReadySeconds: temps m\u00ednim que un pod t\u00e9 que est\u00e0 en estat 'READY' abans de considerar-se disponible. Serveix per donar un temps d'espera entre actualitzaci\u00f3 de cada pod.</p> <p>maxSurge: nombre m\u00e0xim de pods adicionals que es poden crear per sobre de les r\u00e8pliques declarades. Permet un augment d'un pod temporal per sobre de les r\u00e8pliques (3) per facilitar l'actualitzaci\u00f3 gradual sense interrupcions. </p> <p>maxUnavailable: En aquest exemple s'estableix que cap pod, pot estar 'no disponible' a la vegada durant una actualitzaci\u00f3.</p> <p>kubectl apply -f deploy2.yaml</p> <p>kubectl rollout status deployment/my-node-deployment</p> <p>kubectl describe pods | grep 'Image'</p>"},{"location":"local_test/minikube/#mostrar-en-un-navegador-que-my-node-app-sha-actualitzat-a-la-versio-20","title":"Mostrar en un navegador que my-node-app s'ha actualitzat a la versi\u00f3 2.0","text":"<pre><code>kubectl port-forward --address 0.0.0.0 7000:80\nobrir el navegador amb l'adre\u00e7a http://172.16.2.5:7000\n</code></pre>"},{"location":"local_test/minikube/#mostrar-el-dashboard-del-cluster","title":"Mostrar el dashboard del cluster.","text":"<pre><code>minikube dashboard --url &amp;\nkubectl proxy --address=0.0.0.0 --accept-hosts='.*' &amp;\n</code></pre>"},{"location":"remote_test/vps1/","title":"Proves en servidors remots I","text":""},{"location":"remote_test/vps2/","title":"Proves en servidors remots II","text":""}]}